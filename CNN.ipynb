{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2410e49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "34b10db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "img_path = 'sub_images_final/CP3wA5.epi.bmp'\n",
    "# Load color image \n",
    "bgr_img = cv2.imread(img_path)\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "# Normalize, rescale entries to lie in [0,1]\n",
    "gray_img = gray_img.astype(\"float32\")/255\n",
    "# Plot image\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69167d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_path='sub_images_final/CP3wA5.trans.bmp'\n",
    "#img_path = 'sub_images_final/CP3wA5.trans.bmp'\n",
    "# Load color image \n",
    "bgr_img = cv2.imread(img_path)\n",
    "# Convert to grayscale\n",
    "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "# Normalize, rescale entries to lie in [0,1]\n",
    "gray_img = gray_img.astype(\"float32\")/255\n",
    "# Plot image\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "697517a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_to_numeric={}\n",
    "with open(\"family.label.conversion.txt\") as f:\n",
    "    for line in f:\n",
    "      #  print(line)\n",
    "        cat_to_numeric[line.split()[0]]= line.split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "b952a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolate = []\n",
    "family = []\n",
    "with open (\"all.data\") as f:\n",
    "    for line in f:\n",
    "        isolate.append (line.split()[0])\n",
    "        family.append(line.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "eb4087de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=[]\n",
    "for i in range(len(isolate)):\n",
    "    iso=isolate[i]\n",
    "    lab= int(cat_to_numeric[family[i]])\n",
    "    #trans\n",
    "    img_path='sub_images_final/'+iso+'.trans.bmp'\n",
    "    bgr_img = cv2.imread(img_path)\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = gray_img.astype(\"float32\")/255\n",
    "\n",
    "    gray_img_tensor_trans = torch.from_numpy(gray_img).unsqueeze(0)\n",
    "    #epi\n",
    "    img_path='sub_images_final/'+iso+'.epi.bmp'\n",
    "    bgr_img = cv2.imread(img_path)\n",
    "    gray_img_epi = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img_epi = gray_img_epi.astype(\"float32\")/255\n",
    "    gray_img_tensor_epi = torch.from_numpy(gray_img).unsqueeze(0)\n",
    "    \n",
    "    comb_img_tensor=(torch.cat((gray_img_tensor_trans,gray_img_tensor_epi)),lab)\n",
    "    all_data.append(comb_img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "658ea72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 50, 50])"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_img_tensor[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41effad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "928e6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c402d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training classes are: 16\n",
      "number of test classes are: 16\n"
     ]
    }
   ],
   "source": [
    "train_label=[]\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_label.append(train_data[i][1])\n",
    "print(\"number of training classes are:\",len(set(train_label)) )\n",
    "\n",
    "test_label=[]\n",
    "for i in range(len(test_data)):\n",
    "    test_label.append(test_data[i][1])\n",
    "print(\"number of test classes are:\",len(set(test_label)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "3138b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=20, shuffle=True, num_workers=0)\n",
    "test_loader= DataLoader(test_data,  shuffle=True, num_workers=0)\n",
    "#i1, l1 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "14581d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13102"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "751938fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a convolution neural network\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(24)\n",
    "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(24)\n",
    "        self.fc1 = nn.Linear(24*19*19,16 )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = F.relu(self.bn1(self.conv1(input)))      \n",
    "        output = F.relu(self.bn2(self.conv2(output)))     \n",
    "        output = self.pool(output)                        \n",
    "        output = F.relu(self.bn4(self.conv4(output)))     \n",
    "        output = F.relu(self.bn5(self.conv5(output)))   \n",
    "       # print(output.shape)\n",
    "        output = output.view(-1, 24*19*19)\n",
    "      #  print(output.shape)\n",
    "        output = self.fc1(output)\n",
    "       # print(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Instantiate a neural network model \n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "3b04fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    " \n",
    "# Define the loss function with Classification Cross-Entropy loss and an optimizer with Adam optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.000001, weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd1e31",
   "metadata": {},
   "source": [
    "# Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "7a7b81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "# Function to save the model\n",
    "def saveModel():\n",
    "    path = \"./myCNNModel.pth\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# Function to test the model with the test dataset and print the accuracy for the test images\n",
    "predicted_label=[]\n",
    "def testAccuracy():\n",
    "    \n",
    "    model.eval()\n",
    "    accuracy = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "          #  print(labels)\n",
    "            # run the model on the test set to predict labels\n",
    "            outputs = model(images)\n",
    "            # the label with the highest energy will be our prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted_label.append(int(predicted[0]))\n",
    "            total += labels.size(0)\n",
    "            accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    # compute the accuracy over all test images\n",
    "    accuracy = (100 * accuracy / total)\n",
    "    return(accuracy)\n",
    "\n",
    "\n",
    "# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.\n",
    "def train(num_epochs):\n",
    "    \n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Define your execution device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"The model will be running on\", device, \"device\")\n",
    "    # Convert model parameters and buffers to CPU or Cuda\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(train_loader, 0):\n",
    "           # print(labels)\n",
    "            # get the inputs\n",
    "            images = Variable(images.to(device))\n",
    "            labels = Variable(labels.to(device))\n",
    "            #print(labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # predict classes using images from the training set\n",
    "            outputs = model(images)\n",
    "            #print(outputs)\n",
    "            # compute the loss based on model output and real labels\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # backpropagate the loss\n",
    "            loss.backward()\n",
    "            # adjust parameters based on the calculated gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            # Let's print statistics for every 1,000 images\n",
    "            #print(i)\n",
    "            running_loss += loss.item()     # extract the loss value\n",
    "            if i % 500 == 499:    \n",
    "                # print every 1000 (twice per epoch) \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 500))\n",
    "                # zero the loss\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images\n",
    "        accuracy = testAccuracy()\n",
    "        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))\n",
    "        \n",
    "        # we want to save the model if the accuracy is the best\n",
    "        if accuracy > best_accuracy:\n",
    "            saveModel()\n",
    "            best_accuracy = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "846909dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be running on cpu device\n",
      "[1,   500] loss: 1.933\n",
      "For epoch 1 the test accuracy over the whole test set is 38 %\n",
      "[2,   500] loss: 1.901\n",
      "For epoch 2 the test accuracy over the whole test set is 38 %\n",
      "[3,   500] loss: 1.868\n",
      "For epoch 3 the test accuracy over the whole test set is 38 %\n",
      "[4,   500] loss: 1.859\n",
      "For epoch 4 the test accuracy over the whole test set is 38 %\n",
      "[5,   500] loss: 1.858\n",
      "For epoch 5 the test accuracy over the whole test set is 38 %\n",
      "[6,   500] loss: 1.838\n",
      "For epoch 6 the test accuracy over the whole test set is 38 %\n",
      "[7,   500] loss: 1.821\n",
      "For epoch 7 the test accuracy over the whole test set is 39 %\n",
      "[8,   500] loss: 1.825\n",
      "For epoch 8 the test accuracy over the whole test set is 38 %\n",
      "[9,   500] loss: 1.821\n",
      "For epoch 9 the test accuracy over the whole test set is 39 %\n",
      "[10,   500] loss: 1.808\n",
      "For epoch 10 the test accuracy over the whole test set is 38 %\n",
      "[11,   500] loss: 1.808\n",
      "For epoch 11 the test accuracy over the whole test set is 39 %\n",
      "[12,   500] loss: 1.795\n",
      "For epoch 12 the test accuracy over the whole test set is 39 %\n",
      "[13,   500] loss: 1.790\n",
      "For epoch 13 the test accuracy over the whole test set is 39 %\n",
      "[14,   500] loss: 1.787\n",
      "For epoch 14 the test accuracy over the whole test set is 39 %\n",
      "[15,   500] loss: 1.787\n",
      "For epoch 15 the test accuracy over the whole test set is 39 %\n",
      "[16,   500] loss: 1.776\n",
      "For epoch 16 the test accuracy over the whole test set is 39 %\n",
      "[17,   500] loss: 1.770\n",
      "For epoch 17 the test accuracy over the whole test set is 40 %\n",
      "[18,   500] loss: 1.777\n",
      "For epoch 18 the test accuracy over the whole test set is 40 %\n",
      "[19,   500] loss: 1.770\n",
      "For epoch 19 the test accuracy over the whole test set is 40 %\n",
      "[20,   500] loss: 1.755\n",
      "For epoch 20 the test accuracy over the whole test set is 39 %\n",
      "[21,   500] loss: 1.763\n",
      "For epoch 21 the test accuracy over the whole test set is 40 %\n",
      "[22,   500] loss: 1.764\n",
      "For epoch 22 the test accuracy over the whole test set is 40 %\n",
      "[23,   500] loss: 1.762\n",
      "For epoch 23 the test accuracy over the whole test set is 40 %\n",
      "[24,   500] loss: 1.748\n",
      "For epoch 24 the test accuracy over the whole test set is 40 %\n",
      "[25,   500] loss: 1.756\n",
      "For epoch 25 the test accuracy over the whole test set is 40 %\n",
      "[26,   500] loss: 1.742\n",
      "For epoch 26 the test accuracy over the whole test set is 40 %\n",
      "[27,   500] loss: 1.746\n",
      "For epoch 27 the test accuracy over the whole test set is 40 %\n",
      "[28,   500] loss: 1.744\n",
      "For epoch 28 the test accuracy over the whole test set is 40 %\n",
      "[29,   500] loss: 1.746\n",
      "For epoch 29 the test accuracy over the whole test set is 40 %\n",
      "[30,   500] loss: 1.734\n",
      "For epoch 30 the test accuracy over the whole test set is 40 %\n",
      "[31,   500] loss: 1.725\n",
      "For epoch 31 the test accuracy over the whole test set is 40 %\n",
      "[32,   500] loss: 1.728\n",
      "For epoch 32 the test accuracy over the whole test set is 40 %\n",
      "[33,   500] loss: 1.717\n",
      "For epoch 33 the test accuracy over the whole test set is 40 %\n",
      "[34,   500] loss: 1.746\n",
      "For epoch 34 the test accuracy over the whole test set is 40 %\n",
      "[35,   500] loss: 1.730\n",
      "For epoch 35 the test accuracy over the whole test set is 40 %\n",
      "[36,   500] loss: 1.734\n",
      "For epoch 36 the test accuracy over the whole test set is 40 %\n",
      "[37,   500] loss: 1.732\n",
      "For epoch 37 the test accuracy over the whole test set is 40 %\n",
      "[38,   500] loss: 1.719\n",
      "For epoch 38 the test accuracy over the whole test set is 40 %\n",
      "[39,   500] loss: 1.711\n",
      "For epoch 39 the test accuracy over the whole test set is 40 %\n",
      "[40,   500] loss: 1.713\n",
      "For epoch 40 the test accuracy over the whole test set is 40 %\n",
      "[41,   500] loss: 1.714\n",
      "For epoch 41 the test accuracy over the whole test set is 40 %\n",
      "[42,   500] loss: 1.704\n",
      "For epoch 42 the test accuracy over the whole test set is 40 %\n",
      "[43,   500] loss: 1.708\n",
      "For epoch 43 the test accuracy over the whole test set is 40 %\n",
      "[44,   500] loss: 1.713\n",
      "For epoch 44 the test accuracy over the whole test set is 41 %\n",
      "[45,   500] loss: 1.696\n",
      "For epoch 45 the test accuracy over the whole test set is 41 %\n",
      "[46,   500] loss: 1.710\n",
      "For epoch 46 the test accuracy over the whole test set is 40 %\n",
      "[47,   500] loss: 1.700\n",
      "For epoch 47 the test accuracy over the whole test set is 41 %\n",
      "[48,   500] loss: 1.703\n",
      "For epoch 48 the test accuracy over the whole test set is 40 %\n",
      "[49,   500] loss: 1.698\n",
      "For epoch 49 the test accuracy over the whole test set is 40 %\n",
      "[50,   500] loss: 1.701\n",
      "For epoch 50 the test accuracy over the whole test set is 41 %\n",
      "[51,   500] loss: 1.696\n",
      "For epoch 51 the test accuracy over the whole test set is 41 %\n",
      "[52,   500] loss: 1.698\n",
      "For epoch 52 the test accuracy over the whole test set is 41 %\n",
      "[53,   500] loss: 1.698\n",
      "For epoch 53 the test accuracy over the whole test set is 41 %\n",
      "[54,   500] loss: 1.678\n",
      "For epoch 54 the test accuracy over the whole test set is 41 %\n",
      "[55,   500] loss: 1.681\n",
      "For epoch 55 the test accuracy over the whole test set is 41 %\n",
      "[56,   500] loss: 1.694\n",
      "For epoch 56 the test accuracy over the whole test set is 41 %\n",
      "[57,   500] loss: 1.681\n",
      "For epoch 57 the test accuracy over the whole test set is 41 %\n",
      "[58,   500] loss: 1.678\n",
      "For epoch 58 the test accuracy over the whole test set is 41 %\n",
      "[59,   500] loss: 1.683\n",
      "For epoch 59 the test accuracy over the whole test set is 41 %\n",
      "[60,   500] loss: 1.681\n",
      "For epoch 60 the test accuracy over the whole test set is 41 %\n",
      "[61,   500] loss: 1.682\n",
      "For epoch 61 the test accuracy over the whole test set is 41 %\n",
      "[62,   500] loss: 1.673\n",
      "For epoch 62 the test accuracy over the whole test set is 42 %\n",
      "[63,   500] loss: 1.669\n",
      "For epoch 63 the test accuracy over the whole test set is 41 %\n",
      "[64,   500] loss: 1.674\n",
      "For epoch 64 the test accuracy over the whole test set is 41 %\n",
      "[65,   500] loss: 1.679\n",
      "For epoch 65 the test accuracy over the whole test set is 42 %\n",
      "[66,   500] loss: 1.675\n",
      "For epoch 66 the test accuracy over the whole test set is 42 %\n",
      "[67,   500] loss: 1.664\n",
      "For epoch 67 the test accuracy over the whole test set is 42 %\n",
      "[68,   500] loss: 1.658\n",
      "For epoch 68 the test accuracy over the whole test set is 42 %\n",
      "[69,   500] loss: 1.664\n",
      "For epoch 69 the test accuracy over the whole test set is 42 %\n",
      "[70,   500] loss: 1.656\n",
      "For epoch 70 the test accuracy over the whole test set is 42 %\n",
      "[71,   500] loss: 1.654\n",
      "For epoch 71 the test accuracy over the whole test set is 42 %\n",
      "[72,   500] loss: 1.664\n",
      "For epoch 72 the test accuracy over the whole test set is 42 %\n",
      "[73,   500] loss: 1.653\n",
      "For epoch 73 the test accuracy over the whole test set is 42 %\n",
      "[74,   500] loss: 1.655\n",
      "For epoch 74 the test accuracy over the whole test set is 42 %\n",
      "[75,   500] loss: 1.646\n",
      "For epoch 75 the test accuracy over the whole test set is 42 %\n",
      "[76,   500] loss: 1.653\n",
      "For epoch 76 the test accuracy over the whole test set is 42 %\n",
      "[77,   500] loss: 1.660\n",
      "For epoch 77 the test accuracy over the whole test set is 42 %\n",
      "[78,   500] loss: 1.657\n",
      "For epoch 78 the test accuracy over the whole test set is 42 %\n",
      "[79,   500] loss: 1.646\n",
      "For epoch 79 the test accuracy over the whole test set is 42 %\n",
      "[80,   500] loss: 1.643\n",
      "For epoch 80 the test accuracy over the whole test set is 42 %\n",
      "[81,   500] loss: 1.649\n",
      "For epoch 81 the test accuracy over the whole test set is 42 %\n",
      "[82,   500] loss: 1.648\n",
      "For epoch 82 the test accuracy over the whole test set is 42 %\n",
      "[83,   500] loss: 1.636\n",
      "For epoch 83 the test accuracy over the whole test set is 42 %\n",
      "[84,   500] loss: 1.643\n",
      "For epoch 84 the test accuracy over the whole test set is 42 %\n",
      "[85,   500] loss: 1.647\n",
      "For epoch 85 the test accuracy over the whole test set is 42 %\n",
      "[86,   500] loss: 1.626\n",
      "For epoch 86 the test accuracy over the whole test set is 41 %\n",
      "[87,   500] loss: 1.645\n",
      "For epoch 87 the test accuracy over the whole test set is 42 %\n",
      "[88,   500] loss: 1.639\n",
      "For epoch 88 the test accuracy over the whole test set is 42 %\n",
      "[89,   500] loss: 1.641\n",
      "For epoch 89 the test accuracy over the whole test set is 42 %\n",
      "[90,   500] loss: 1.636\n",
      "For epoch 90 the test accuracy over the whole test set is 42 %\n",
      "[91,   500] loss: 1.635\n",
      "For epoch 91 the test accuracy over the whole test set is 42 %\n",
      "[92,   500] loss: 1.626\n",
      "For epoch 92 the test accuracy over the whole test set is 42 %\n",
      "[93,   500] loss: 1.621\n",
      "For epoch 93 the test accuracy over the whole test set is 42 %\n",
      "[94,   500] loss: 1.624\n",
      "For epoch 94 the test accuracy over the whole test set is 42 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95,   500] loss: 1.624\n",
      "For epoch 95 the test accuracy over the whole test set is 42 %\n",
      "[96,   500] loss: 1.617\n",
      "For epoch 96 the test accuracy over the whole test set is 42 %\n",
      "[97,   500] loss: 1.613\n",
      "For epoch 97 the test accuracy over the whole test set is 42 %\n",
      "[98,   500] loss: 1.614\n",
      "For epoch 98 the test accuracy over the whole test set is 42 %\n",
      "[99,   500] loss: 1.625\n",
      "For epoch 99 the test accuracy over the whole test set is 42 %\n",
      "[100,   500] loss: 1.613\n",
      "For epoch 100 the test accuracy over the whole test set is 42 %\n"
     ]
    }
   ],
   "source": [
    " train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "12270adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "path = \"myCNNModel.pth\"\n",
    "model.load_state_dict(torch.load(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "8976aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = testAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "1efe13a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.918192918192915\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "7020fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through each family, calculate TP, FP, TN, FN\n",
    "results={}\n",
    "for i in set(test_label):\n",
    "    #print(i)\n",
    "    #true positive:\n",
    "    tp=0\n",
    "    fp=0\n",
    "    tn=0\n",
    "    fn=0\n",
    "    for c in range(len(predicted_label)):\n",
    "        if predicted_label[c] == i:\n",
    "            if test_label[c]==i:\n",
    "                tp+=1\n",
    "            else:\n",
    "                fp+=1\n",
    "        else:\n",
    "            if test_label[c]!=i:\n",
    "                tn+=1\n",
    "            else:\n",
    "                fn+=1\n",
    "    prec=0\n",
    "    rec=0\n",
    "    if (tp+fp) >0:\n",
    "        prec= tp/(tp+fp)\n",
    "    if (tp+fn)>0:\n",
    "        rec=tp/(tp+fn)\n",
    "    results[i]=[tp, fp, tn, fn, prec,rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "9f2ac102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [627, 1119, 1001, 529, 0.359106529209622, 0.5423875432525952],\n",
       " 1: [218, 803, 1712, 543, 0.21351616062683643, 0.2864651773981603],\n",
       " 2: [17, 211, 2831, 217, 0.07456140350877193, 0.07264957264957266],\n",
       " 3: [2, 88, 2964, 222, 0.022222222222222223, 0.008928571428571428],\n",
       " 4: [0, 3, 3094, 179, 0.0, 0.0],\n",
       " 5: [2, 41, 3103, 130, 0.046511627906976744, 0.015151515151515152],\n",
       " 6: [1, 10, 3169, 96, 0.09090909090909091, 0.010309278350515464],\n",
       " 7: [1, 31, 3158, 86, 0.03125, 0.011494252873563218],\n",
       " 8: [0, 0, 3183, 93, 0, 0.0],\n",
       " 9: [0, 13, 3176, 87, 0.0, 0.0],\n",
       " 10: [0, 44, 3187, 45, 0.0, 0.0],\n",
       " 11: [0, 0, 3236, 40, 0, 0.0],\n",
       " 12: [0, 0, 3264, 12, 0, 0.0],\n",
       " 13: [0, 1, 3262, 13, 0.0, 0.0],\n",
       " 14: [0, 0, 3271, 5, 0, 0.0],\n",
       " 15: [2, 42, 3123, 109, 0.045454545454545456, 0.018018018018018018]}"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
